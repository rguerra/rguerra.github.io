<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="rguerra" />


<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="site_libs/highlight/textmate.css"
      type="text/css" />
<script src="site_libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="_resources/css/styles.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>

<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="site_libs/navigation-1.0/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.9em;
  padding-left: 5px;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
  padding-left: 10px;
}

</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">My Personal Website</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<div id="soft-max" class="section level1">
<h1>Soft Max</h1>
<p>Many thanks to Charles Yang for his quora post <span class="citation">(Zheng 2016)</span> that I am basically pasting here because it is so well explained.</p>
<div id="original-definition-according-to-quora-softmax" class="section level2">
<h2>Original definition according to <span class="citation">(Zheng 2016)</span></h2>
<div id="what-is-max" class="section level3">
<h3>What is Max?</h3>
<p><strong>Max</strong> is a function from <span class="math">\(\mathbb{R}^n \Rightarrow \mathbb{R}\)</span>. <span class="math">\[max(x_1,...,x_n) = y\]</span></p>
<p>However, <strong>max</strong> is not differentiable. Therefore in many applications one uses the function:</p>
<p><span class="math">\[\text{softmax}(x_1,...,x_n)=log\big(\sum\limits_{i=1}^ne^{x_i}\big)\]</span></p>
<p>To understand what is happening, lets picture in the <span class="math">\(x,y\)</span> plane the graph of: <span class="math">\[max(x, 5) = y\]</span> The graph an intersection of two lines (a horizontal one and a 45 degree one) at an elbow. For all values of <span class="math">\(x \le 5\)</span>, <span class="math">\(max(x,5)\)</span> is equal to 5. In other words it is a horizontal line. The elbow of the graph is when <span class="math">\(x=5\)</span> because for all values of <span class="math">\(x \gt 5\)</span> <span class="math">\(max(x,5)\)</span> is equal to <span class="math">\(x\)</span>. So it is a 45 degree straight line <span class="math">\(x = y\)</span>.</p>
<p>A graph with an elbow is not differentiable, so a differentiable approximation is <strong>softmax</strong>.</p>
<p>As <span class="citation">(Zheng 2016)</span> mentions, you can also rescale the softmax to better approximate the function. For <span class="math">\(k \gt 0\)</span>, define</p>
<p><span class="math">\[k−\text{softmax}(x_1,...,x_n)=\frac{1}{k}log\big(\sum\limits_{i=1}^ne^{kx_i}\big)\]</span></p>
<p>Then as <span class="math">\(k\)</span> increases, you get a better approximation of max from softmax: however, this comes at a cost of increasing the roughness (size of derivatives) of the function.</p>
</div>
</div>
<div id="machine-learning-definition" class="section level2">
<h2>Machine Learning Definition</h2>
<p>I am just copying the definition and explanation from <span class="citation">(Zheng 2016)</span> but I really like the way it is explained.</p>
<p>According to <span class="citation">(Zheng 2016)</span>, in machine learning <strong>softmax</strong> is used for classification. Suppose you have <span class="math">\(n\)</span> classes. For any given feature <span class="math">\(x\)</span>, you want to estimate its probabilities <span class="math">\(p_i\)</span> of being in class <span class="math">\(i\)</span>. However, your algorithm doesn’t directly produce probabilities. Instead it first produces real-valued scores <span class="math">\(y_1,...,y_n\)</span>.From these scores you define the probabilities <span class="math">\(p_i\)</span> using the softmax function.</p>
<p><span class="math">\[(p_1,...,p_n) = \text{softmax}(y_1,...,y_n) = \Big(\frac{e^{y_1}}{\sum\limits_{j=1}^ne^{y_j}},...,\frac{e^{y_n}}{\sum\limits_{j=1}^ne^{y_j}}\Big) \]</span></p>
<p>Furthermore according to <span class="citation">(Zheng 2016)</span>, why set up your classifier this way? Because a probability vector <span class="math">\((p_1,...,p_n)\)</span> lives in a very constrained space (nonnegative, sums to 1), and it’s hard to work with functions that map from the feature space to this constrained space. In particular, the sum-to-one constraint means that you can’t train learners for each class separately. Instead, you work with functions that map to the unconstrained space of scores <span class="math">\((y_1,...,y_n)\)</span>, and then map those scores to the space of probability vectors in the last step. This allows you to divide up the problem into <span class="math">\(n\)</span> subproblems of predicting <span class="math">\(y_1,...,y_n\)</span>, and it’s also a generalization of logistic regression.</p>
</div>
<div id="relation-of-both-definitions" class="section level2">
<h2>Relation of both definitions</h2>
<p>As you can note the formula for <strong>softmax</strong> in both definitions is different.</p>
<ul>
<li><p>Original Def. (<strong>Softmax</strong>): <span class="math">\[\text{softmax}(x_1,...,x_n)=log\big(\sum\limits_{i=1}^ne^{x_i}\big)\]</span></p></li>
<li><p>Machine Learning Def. (<strong>Softmax Gradient</strong>): <span class="math">\[\text{softmax}(x_1,...,x_n) = \Big(\frac{e^{x_1}}{\sum\limits_{j=1}^ne^{x_j}},...,\frac{e^{x_n}}{\sum\limits_{j=1}^ne^{x_j}}\Big) \]</span></p></li>
</ul>
<p>It turns out that one is the gradient of the other.</p>
<div class="references">
<h1>REFERENCE</h1>
<p>Zheng, Charles Yang. 2016. <em>What Does the Term “Soft-Max” Mean in the Context of Machine Learning?</em> Quora. <a href="https://www.quora.com/What-does-the-term-soft-max-mean-in-the-context-of-machine-learning" class="uri">https://www.quora.com/What-does-the-term-soft-max-mean-in-the-context-of-machine-learning</a>.</p>
</div>
</div>
</div>


<p>Copyright &copy; 2016 Raul Guerra, Inc. All rights reserved.</p>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
